# life is short, you need use python to create something!
# author    TuringEmmy
# time      11/26/18 9:45 PM
# project   DeepLearingStudy

# Relu的激活函数


# Pooling层主要的作用是特征提取，通股欧去掉Feature Map中不重要的样本，进一步减少参数。Pooling的方法很多，最常用的是Max Pooling


# Full Connected层
# 全连接层在整个卷积神经网络中起到“分类器”的作用

print("*" * 100)
# 卷积层
# 激活
# 池化
# 全链接
print("*" * 100)
